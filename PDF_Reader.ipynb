{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting text from PDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To read the PDF\n",
    "import PyPDF2\n",
    "# To analyze the PDF layout and extract text\n",
    "from pdfminer.high_level import extract_pages, extract_text\n",
    "from pdfminer.layout import LTTextContainer, LTChar, LTRect, LTFigure\n",
    "# To extract text from tables in PDF\n",
    "import pdfplumber\n",
    "# To extract the images from the PDFs\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "# To perform OCR to extract text from images \n",
    "import pytesseract \n",
    "# To remove the additional created files\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to extract text\n",
    "\n",
    "def text_extraction(element):\n",
    "    # Extracting the text from the in line text element\n",
    "    line_text = element.get_text()\n",
    "    \n",
    "    # Find the formats of the text\n",
    "    # Initialize the list with all the formats appeared in the line of text\n",
    "    line_formats = []\n",
    "    for text_line in element:\n",
    "        if isinstance(text_line, LTTextContainer):\n",
    "            # Iterating through each character in the line of text\n",
    "            for character in text_line:\n",
    "                if isinstance(character, LTChar):\n",
    "                    # Append the font name of the character\n",
    "                    line_formats.append(character.fontname)\n",
    "                    # Append the font size of the character\n",
    "                    line_formats.append(character.size)\n",
    "    # Find the unique font sizes and names in the line\n",
    "    format_per_line = list(set(line_formats))\n",
    "    \n",
    "    # Return a tuple with the text in each line along with its format\n",
    "    return (line_text, format_per_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting tables from the page\n",
    "\n",
    "def extract_table(pdf_path, page_num, table_num):\n",
    "    # Open the pdf file\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    # Find the examined page\n",
    "    table_page = pdf.pages[page_num]\n",
    "    # Extract the appropriate table\n",
    "    table = table_page.extract_tables()[table_num]\n",
    "    \n",
    "    return table\n",
    "\n",
    "# Convert table into appropriate fromat\n",
    "def table_converter(table):\n",
    "    table_string = ''\n",
    "    # Iterate through each row of the table\n",
    "    for row_num in range(len(table)):\n",
    "        row = table[row_num]\n",
    "        # Remove the line breaker from the wrapted texts\n",
    "        cleaned_row = [item.replace('\\n', ' ') if item is not None and '\\n' in item else 'None' if item is None else item for item in row]\n",
    "        # Convert the table into a string \n",
    "        table_string+=('|'+'|'.join(cleaned_row)+'|'+'\\n')\n",
    "    # Removing the last line break\n",
    "    table_string = table_string[:-1]\n",
    "    return table_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to crop the image elements from PDFs\n",
    "def crop_image(element, pageObj):\n",
    "    # Get the coordinates to crop the image from PDF\n",
    "    [image_left, image_top, image_right, image_bottom] = [element.x0,element.y0,element.x1,element.y1] \n",
    "    # Crop the page using coordinates (left, bottom, right, top)\n",
    "    pageObj.mediabox.lower_left = (image_left, image_bottom)\n",
    "    pageObj.mediabox.upper_right = (image_right, image_top)\n",
    "    # Save the cropped page to a new PDF\n",
    "    cropped_pdf_writer = PyPDF2.PdfWriter()\n",
    "    cropped_pdf_writer.add_page(pageObj)\n",
    "    # Save the cropped PDF to a new file\n",
    "    with open('cropped_image.pdf', 'wb') as cropped_pdf_file:\n",
    "        cropped_pdf_writer.write(cropped_pdf_file)\n",
    "\n",
    "# Create a function to convert the PDF to images\n",
    "def convert_to_images(input_file,):\n",
    "    images = convert_from_path(input_file)\n",
    "    image = images[0]\n",
    "    output_file = 'PDF_image.png'\n",
    "    image.save(output_file, 'PNG')\n",
    "\n",
    "# Create a function to read text from images\n",
    "def image_to_text(image_path):\n",
    "    # Read the image\n",
    "    img = Image.open(image_path)\n",
    "    # Extract the text from the image\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the PDF path\n",
    "pdf_path = 'Example PDF.pdf'\n",
    "\n",
    "# Create a pdf file object\n",
    "pdfFileObj = open(pdf_path, 'rb')\n",
    "# Create a pdf reader object\n",
    "pdfReaded = PyPDF2.PdfReader(pdfFileObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dictionary to extract text from each image\n",
    "text_per_page = {}\n",
    "# Create a boolean variable for image detection\n",
    "image_flag = False\n",
    "\n",
    "# We extract the pages from the PDF\n",
    "for pagenum, page in enumerate(extract_pages(pdf_path)):\n",
    "    \n",
    "    # Initialize the variables needed for the text extraction from the page\n",
    "    pageObj = pdfReaded.pages[pagenum]\n",
    "    page_text = []\n",
    "    line_format = []\n",
    "    text_from_images = []\n",
    "    text_from_tables = []\n",
    "    page_content = []\n",
    "    # Initialize the number of the examined tables\n",
    "    table_num = 0\n",
    "    first_element= True\n",
    "    table_extraction_flag= False\n",
    "    # Open the pdf file\n",
    "    pdf = pdfplumber.open(pdf_path)\n",
    "    # Find the examined page\n",
    "    page_tables = pdf.pages[pagenum]\n",
    "    # Find the number of tables in the page\n",
    "    tables = page_tables.find_tables()\n",
    "\n",
    "\n",
    "    # Find all the elements\n",
    "    page_elements = [(element.y1, element) for element in page._objs]\n",
    "    # Sort all the element as they appear in the page \n",
    "    page_elements.sort(key=lambda a: a[0], reverse=True)\n",
    "\n",
    "    # Find the elements that composed a page\n",
    "    for i,component in enumerate(page_elements):\n",
    "        # Extract the position of the top side of the element in PDF\n",
    "        pos= component[0]\n",
    "        # Extract the element of the page layout\n",
    "        element = component[1]\n",
    "        \n",
    "        # Check if the element is text element\n",
    "        if isinstance(element, LTTextContainer):\n",
    "            # Check if the text appeared in a table\n",
    "            if table_extraction_flag == False:\n",
    "                # Use the function to extract the text and format for each text element\n",
    "                (line_text, format_per_line) = text_extraction(element)\n",
    "                # Append the text of each line to the page text\n",
    "                page_text.append(line_text)\n",
    "                # Append the format for each line containing text\n",
    "                line_format.append(format_per_line)\n",
    "                page_content.append(line_text)\n",
    "            else:\n",
    "                # Omit the text that appeared in a table\n",
    "                pass\n",
    "\n",
    "        # Check the elements for images\n",
    "        if isinstance(element, LTFigure):\n",
    "            # Crop the image from PDF\n",
    "            crop_image(element, pageObj)\n",
    "            # Convert the croped pdf to image\n",
    "            convert_to_images('cropped_image.pdf')\n",
    "            # Extract the text from image\n",
    "            image_text = image_to_text('PDF_image.png')\n",
    "            text_from_images.append(image_text)\n",
    "            page_content.append(image_text)\n",
    "            # Add a placeholder in the text and format lists\n",
    "            page_text.append('image')\n",
    "            line_format.append('image')\n",
    "            # Update the flag for image detection\n",
    "            image_flag = True\n",
    "\n",
    "        # Check the elements for tables\n",
    "        if isinstance(element, LTRect):\n",
    "            # If first rectacular element\n",
    "            if first_element == True and (table_num+1) <= len(tables):\n",
    "                # Find the bounding box of the table\n",
    "                lower_side = page.bbox[3] - tables[table_num].bbox[3]\n",
    "                upper_side = element.y1 \n",
    "                # Extract the information of the table\n",
    "                table = extract_table(pdf_path, pagenum, table_num)\n",
    "                # Convert the table information in structured string format\n",
    "                table_string = table_converter(table)\n",
    "                # Append the table string into a list\n",
    "                text_from_tables.append(table_string)\n",
    "                page_content.append(table_string)\n",
    "                # Set the flag as True to avoid the content again\n",
    "                table_extraction_flag = True\n",
    "                # Make it other element\n",
    "                first_element = False\n",
    "                # Add a placeholder in the text and format lists\n",
    "                page_text.append('table')\n",
    "                line_format.append('table')\n",
    "\n",
    "            # Check if we alread extracted the tables from the page\n",
    "            if element.y0 >= lower_side and element.y1 <= upper_side:\n",
    "                pass\n",
    "            elif not isinstance(page_elements[i+1][1], LTRect):\n",
    "                table_extraction_flag = False\n",
    "                first_element = True\n",
    "                table_num+=1\n",
    "\n",
    "\n",
    "    # Create the key of the dictionary\n",
    "    dctkey = 'Page_'+str(pagenum)\n",
    "    # Add the list of list as value of the page key\n",
    "    text_per_page[dctkey]= [page_text, line_format, text_from_images,text_from_tables, page_content]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the pdf file object\n",
    "pdfFileObj.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the additional files created if image is detected\n",
    "if image_flag:\n",
    "    os.remove('cropped_image.pdf')\n",
    "    os.remove('PDF_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample\n",
      "\n",
      "Logo Text\n",
      "\n",
      " \n",
      " \n",
      "This is an example title. \n",
      " \n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor \n",
      "incididunt  ut  labore  et  dolore  magna  aliqua.  Ut  enim  ad  minim  veniam,  quis \n",
      "nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. \n",
      "Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu \n",
      "fugiat  nulla  pariatur.  Excepteur  sint  occaecat  cupidatat  non  proident,  sunt  in \n",
      "culpa qui officia deserunt mollit anim id est laborum. \n",
      " \n",
      " \n",
      "|Title 1 with a longer title than usual|Title 2|Title 3|\n",
      "|Value 11|Value 12|Value 13|\n",
      "|Value 21|Value 22|Value 23| \n",
      " \n",
      "Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor \n",
      "incididunt  ut  labore  et  dolore  magna  aliqua.  Ut  enim  ad  minim  veniam,  quis \n",
      "nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. \n",
      "Duis  aute  irure  dolor  in  reprehenderit  in  voluptate  velit  esse  cillum  dolore  eu \n",
      "fugiat  nulla  pariatur.  Excepteur  sint  occaecat  cupidatat  non  proident,  sunt  in \n",
      "culpa qui officia deserunt mollit anim id est laborum. \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the content of the page\n",
    "result = ''.join(text_per_page['Page_0'][4])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18e1f6b75012c804af28ad83a5c9691a3f91030522fe6d37827743bbd4743ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
